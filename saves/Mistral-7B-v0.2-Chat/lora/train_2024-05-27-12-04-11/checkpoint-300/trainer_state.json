{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.2857142857142856,
  "eval_steps": 500,
  "global_step": 300,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0380952380952381,
      "grad_norm": 6.944857120513916,
      "learning_rate": 4.9992811366328926e-05,
      "loss": 4.7161,
      "step": 5
    },
    {
      "epoch": 0.0761904761904762,
      "grad_norm": 7.338119029998779,
      "learning_rate": 4.997124959943201e-05,
      "loss": 4.1929,
      "step": 10
    },
    {
      "epoch": 0.11428571428571428,
      "grad_norm": 7.696468353271484,
      "learning_rate": 4.993532709928075e-05,
      "loss": 3.4368,
      "step": 15
    },
    {
      "epoch": 0.1523809523809524,
      "grad_norm": 4.544597148895264,
      "learning_rate": 4.9885064524570665e-05,
      "loss": 2.567,
      "step": 20
    },
    {
      "epoch": 0.19047619047619047,
      "grad_norm": 3.1456966400146484,
      "learning_rate": 4.982049078084071e-05,
      "loss": 2.0952,
      "step": 25
    },
    {
      "epoch": 0.22857142857142856,
      "grad_norm": 2.2230734825134277,
      "learning_rate": 4.974164300384998e-05,
      "loss": 1.825,
      "step": 30
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 1.9935892820358276,
      "learning_rate": 4.964856653822122e-05,
      "loss": 1.6839,
      "step": 35
    },
    {
      "epoch": 0.3047619047619048,
      "grad_norm": 1.4216827154159546,
      "learning_rate": 4.954131491136362e-05,
      "loss": 1.6191,
      "step": 40
    },
    {
      "epoch": 0.34285714285714286,
      "grad_norm": 1.180444359779358,
      "learning_rate": 4.9419949802689666e-05,
      "loss": 1.4999,
      "step": 45
    },
    {
      "epoch": 0.38095238095238093,
      "grad_norm": 1.2254300117492676,
      "learning_rate": 4.92845410081439e-05,
      "loss": 1.488,
      "step": 50
    },
    {
      "epoch": 0.41904761904761906,
      "grad_norm": 1.1648893356323242,
      "learning_rate": 4.913516640006392e-05,
      "loss": 1.449,
      "step": 55
    },
    {
      "epoch": 0.45714285714285713,
      "grad_norm": 1.1051982641220093,
      "learning_rate": 4.897191188239667e-05,
      "loss": 1.4369,
      "step": 60
    },
    {
      "epoch": 0.49523809523809526,
      "grad_norm": 1.0394572019577026,
      "learning_rate": 4.8794871341296e-05,
      "loss": 1.3994,
      "step": 65
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 1.0529628992080688,
      "learning_rate": 4.8604146591129485e-05,
      "loss": 1.4229,
      "step": 70
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 0.9676260352134705,
      "learning_rate": 4.8399847315926e-05,
      "loss": 1.368,
      "step": 75
    },
    {
      "epoch": 0.6095238095238096,
      "grad_norm": 0.99428790807724,
      "learning_rate": 4.818209100629745e-05,
      "loss": 1.4061,
      "step": 80
    },
    {
      "epoch": 0.6476190476190476,
      "grad_norm": 1.008302927017212,
      "learning_rate": 4.795100289187099e-05,
      "loss": 1.3476,
      "step": 85
    },
    {
      "epoch": 0.6857142857142857,
      "grad_norm": 1.16199791431427,
      "learning_rate": 4.7706715869270635e-05,
      "loss": 1.4022,
      "step": 90
    },
    {
      "epoch": 0.7238095238095238,
      "grad_norm": 1.1098365783691406,
      "learning_rate": 4.74493704256897e-05,
      "loss": 1.4272,
      "step": 95
    },
    {
      "epoch": 0.7619047619047619,
      "grad_norm": 1.1421867609024048,
      "learning_rate": 4.717911455809782e-05,
      "loss": 1.3773,
      "step": 100
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.1274964809417725,
      "learning_rate": 4.6896103688129385e-05,
      "loss": 1.3565,
      "step": 105
    },
    {
      "epoch": 0.8380952380952381,
      "grad_norm": 1.228756070137024,
      "learning_rate": 4.660050057270191e-05,
      "loss": 1.4167,
      "step": 110
    },
    {
      "epoch": 0.8761904761904762,
      "grad_norm": 1.3438767194747925,
      "learning_rate": 4.6292475210416106e-05,
      "loss": 1.3369,
      "step": 115
    },
    {
      "epoch": 0.9142857142857143,
      "grad_norm": 1.4329936504364014,
      "learning_rate": 4.597220474379125e-05,
      "loss": 1.389,
      "step": 120
    },
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 1.1872899532318115,
      "learning_rate": 4.563987335739216e-05,
      "loss": 1.3591,
      "step": 125
    },
    {
      "epoch": 0.9904761904761905,
      "grad_norm": 1.1809924840927124,
      "learning_rate": 4.5295672171906364e-05,
      "loss": 1.3123,
      "step": 130
    },
    {
      "epoch": 1.0285714285714285,
      "grad_norm": 1.2801074981689453,
      "learning_rate": 4.49397991342324e-05,
      "loss": 1.3789,
      "step": 135
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 1.1991734504699707,
      "learning_rate": 4.4572458903642354e-05,
      "loss": 1.42,
      "step": 140
    },
    {
      "epoch": 1.1047619047619048,
      "grad_norm": 1.2432416677474976,
      "learning_rate": 4.419386273408428e-05,
      "loss": 1.3355,
      "step": 145
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 1.2829079627990723,
      "learning_rate": 4.3804228352691935e-05,
      "loss": 1.3584,
      "step": 150
    },
    {
      "epoch": 1.180952380952381,
      "grad_norm": 1.2974241971969604,
      "learning_rate": 4.3403779834572004e-05,
      "loss": 1.3237,
      "step": 155
    },
    {
      "epoch": 1.2190476190476192,
      "grad_norm": 1.3027797937393188,
      "learning_rate": 4.2992747473940556e-05,
      "loss": 1.2919,
      "step": 160
    },
    {
      "epoch": 1.2571428571428571,
      "grad_norm": 1.2726106643676758,
      "learning_rate": 4.2571367651683e-05,
      "loss": 1.3017,
      "step": 165
    },
    {
      "epoch": 1.2952380952380953,
      "grad_norm": 1.3997727632522583,
      "learning_rate": 4.213988269941362e-05,
      "loss": 1.3116,
      "step": 170
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 1.3294004201889038,
      "learning_rate": 4.169854076011292e-05,
      "loss": 1.2453,
      "step": 175
    },
    {
      "epoch": 1.3714285714285714,
      "grad_norm": 1.3473143577575684,
      "learning_rate": 4.124759564542295e-05,
      "loss": 1.3084,
      "step": 180
    },
    {
      "epoch": 1.4095238095238094,
      "grad_norm": 1.458443284034729,
      "learning_rate": 4.078730668968253e-05,
      "loss": 1.3098,
      "step": 185
    },
    {
      "epoch": 1.4476190476190476,
      "grad_norm": 1.3824541568756104,
      "learning_rate": 4.031793860078649e-05,
      "loss": 1.2579,
      "step": 190
    },
    {
      "epoch": 1.4857142857142858,
      "grad_norm": 1.440774917602539,
      "learning_rate": 3.9839761307954675e-05,
      "loss": 1.3433,
      "step": 195
    },
    {
      "epoch": 1.5238095238095237,
      "grad_norm": 1.5485877990722656,
      "learning_rate": 3.935304980649813e-05,
      "loss": 1.2508,
      "step": 200
    },
    {
      "epoch": 1.561904761904762,
      "grad_norm": 1.5197304487228394,
      "learning_rate": 3.8858083999671855e-05,
      "loss": 1.2134,
      "step": 205
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.5307598114013672,
      "learning_rate": 3.835514853770505e-05,
      "loss": 1.2832,
      "step": 210
    },
    {
      "epoch": 1.638095238095238,
      "grad_norm": 1.5560933351516724,
      "learning_rate": 3.784453265410141e-05,
      "loss": 1.3367,
      "step": 215
    },
    {
      "epoch": 1.6761904761904762,
      "grad_norm": 1.5821003913879395,
      "learning_rate": 3.732652999930364e-05,
      "loss": 1.2754,
      "step": 220
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 1.5839283466339111,
      "learning_rate": 3.680143847181783e-05,
      "loss": 1.2333,
      "step": 225
    },
    {
      "epoch": 1.7523809523809524,
      "grad_norm": 1.4573651552200317,
      "learning_rate": 3.6269560046894766e-05,
      "loss": 1.2774,
      "step": 230
    },
    {
      "epoch": 1.7904761904761903,
      "grad_norm": 1.586928367614746,
      "learning_rate": 3.573120060286679e-05,
      "loss": 1.2047,
      "step": 235
    },
    {
      "epoch": 1.8285714285714287,
      "grad_norm": 1.5990291833877563,
      "learning_rate": 3.5186669745240026e-05,
      "loss": 1.2822,
      "step": 240
    },
    {
      "epoch": 1.8666666666666667,
      "grad_norm": 1.5958616733551025,
      "learning_rate": 3.463628062864312e-05,
      "loss": 1.2697,
      "step": 245
    },
    {
      "epoch": 1.9047619047619047,
      "grad_norm": 1.5590704679489136,
      "learning_rate": 3.4080349776734925e-05,
      "loss": 1.2566,
      "step": 250
    },
    {
      "epoch": 1.9428571428571428,
      "grad_norm": 1.6620049476623535,
      "learning_rate": 3.351919690017473e-05,
      "loss": 1.2494,
      "step": 255
    },
    {
      "epoch": 1.980952380952381,
      "grad_norm": 1.612534999847412,
      "learning_rate": 3.2953144712759545e-05,
      "loss": 1.2742,
      "step": 260
    },
    {
      "epoch": 2.019047619047619,
      "grad_norm": 1.7506952285766602,
      "learning_rate": 3.238251874583452e-05,
      "loss": 1.1955,
      "step": 265
    },
    {
      "epoch": 2.057142857142857,
      "grad_norm": 1.6620182991027832,
      "learning_rate": 3.1807647161082795e-05,
      "loss": 1.2359,
      "step": 270
    },
    {
      "epoch": 2.0952380952380953,
      "grad_norm": 1.7702277898788452,
      "learning_rate": 3.122886056180284e-05,
      "loss": 1.2571,
      "step": 275
    },
    {
      "epoch": 2.1333333333333333,
      "grad_norm": 1.7801717519760132,
      "learning_rate": 3.064649180278152e-05,
      "loss": 1.2468,
      "step": 280
    },
    {
      "epoch": 2.1714285714285713,
      "grad_norm": 1.8492077589035034,
      "learning_rate": 3.006087579887244e-05,
      "loss": 1.2642,
      "step": 285
    },
    {
      "epoch": 2.2095238095238097,
      "grad_norm": 1.9339889287948608,
      "learning_rate": 2.9472349332389525e-05,
      "loss": 1.2248,
      "step": 290
    },
    {
      "epoch": 2.2476190476190476,
      "grad_norm": 1.829075813293457,
      "learning_rate": 2.8881250859426646e-05,
      "loss": 1.1951,
      "step": 295
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 1.8561389446258545,
      "learning_rate": 2.8287920315214643e-05,
      "loss": 1.2722,
      "step": 300
    }
  ],
  "logging_steps": 5,
  "max_steps": 655,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1537629578028646e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
